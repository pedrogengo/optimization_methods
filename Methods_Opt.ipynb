{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos - Otimização CEDS 2019\n",
    "\n",
    "Este *notebook* visa à criação de uma classe que incorpore os métodos vistos e abordados para a resolução de problemas de otimização. Sendo assim, a escolha de cada possibilidade fica a critério do usuário, o qual precisa apenas fornecer a função, o gradiente e a hessiana (quando disponíveis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando bibliotecas úteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando funcionalidade de derivação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*x\n",
      "4*w\n"
     ]
    }
   ],
   "source": [
    "x = Symbol('x')\n",
    "w = Symbol('w')\n",
    "y = x**2 + 2*w**2\n",
    "partial_x = y.diff(x)\n",
    "partial_w = y.diff(w)\n",
    "print(partial_x)\n",
    "print(partial_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo função, gradiente e hessiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0]**2+2*x[1]**2\n",
    "\n",
    "def grad(x):\n",
    "    output = np.zeros(x.shape[0])\n",
    "    \n",
    "    output[0] = 2*x[0]\n",
    "    output[1] = 4*x[1]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def hess(x):\n",
    "    output = np.zeros((x.shape[0], x.shape[0]))\n",
    "    \n",
    "    output[0,0] = 2\n",
    "    output[0,1] = 0\n",
    "    output[1,0] = 0\n",
    "    output[1,1] = 4\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe de métodos de otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization():\n",
    "    '''\n",
    "    Class designed for solving a minimization problem.\\n\n",
    "    Initialization requires:\n",
    "    >>> Function\n",
    "    >>> Gradient\n",
    "    >>> Hessian (optional)\n",
    "    >>> max_iter (optional)\n",
    "    >>> precision (optional)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, function, gradient, hessian=None, max_iter=4, precision=1e-5):\n",
    "        self.f = function\n",
    "        self.grad = gradient\n",
    "        self.hess = hessian\n",
    "        self.max_iter = max_iter\n",
    "        self.precision = precision\n",
    "        \n",
    "    def GradientDescent(self, x0, method='cauchy', t0=None, backtracking=False, alpha=0.1):\n",
    "        '''\n",
    "        Gradient Descent method.\n",
    "        >>> x0: initial approximation\n",
    "        >>> method: ('cauchy', 'constant')\n",
    "        >>> t: required if method 'constant' is selected\n",
    "        >>> backtracking: (True, False)\n",
    "        >>> alpha: value needed if backtracking = True\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.ts = []\n",
    "        self.xs = []\n",
    "        \n",
    "        self.xs.append(x0)\n",
    "        self.funcs.append(self.f(x0))\n",
    "        self.grads.append(self.grad(x0))\n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        \n",
    "        if method=='cauchy':\n",
    "            \n",
    "            for i in range(self.max_iter):\n",
    "                t = self.grads[-1]@self.grads[-1]/(self.grads[-1].T@self.hess(x0)@self.grads[-1])\n",
    "                if backtracking==True:\n",
    "                    while self.f(x0-t*self.grads[-1]) >= self.f(x0)-t*alpha*(self.grads[-1]@self.grads[-1]):\n",
    "                        t/=2\n",
    "                self.ts.append(t)\n",
    "                \n",
    "                x = x0 - t*self.grads[-1]\n",
    "                \n",
    "                self.xs.append(x)\n",
    "                self.funcs.append(self.f(x))\n",
    "                self.grads.append(self.grad(x))\n",
    "                self.directions.append(-self.grads[-1])\n",
    "                self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                x0 = x\n",
    "                \n",
    "                if self.grad_norms[-1] < self.precision:\n",
    "                    break\n",
    "                \n",
    "        elif method=='constant':\n",
    "            \n",
    "            for i in range(self.max_iter):\n",
    "                t=t0\n",
    "                if backtracking==True:\n",
    "                    while self.f(x0-t*self.grads[-1]) >= self.f(x0)-t*alpha*(self.grads[-1]@self.grads[-1]):\n",
    "                        t=t/2\n",
    "                self.ts.append(t)\n",
    "                \n",
    "                x = x0 - t*self.grads[-1]\n",
    "                \n",
    "                self.xs.append(x)\n",
    "                self.funcs.append(self.f(x))\n",
    "                self.grads.append(self.grad(x))\n",
    "                self.directions.append(-self.grads[-1])\n",
    "                self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                x0 = x\n",
    "                \n",
    "                if self.grad_norms[-1] < self.precision:\n",
    "                    break\n",
    "                \n",
    "        else:\n",
    "            raise ValueError('Method not found!')\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO DO GRADIENTE')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def CGLinear(self, x0):\n",
    "        '''\n",
    "        Linear CG method.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.ts = []\n",
    "        self.xs = []\n",
    "        \n",
    "        self.xs.append(x0)\n",
    "        self.funcs.append(self.f(x0))\n",
    "        self.grads.append(self.grad(x0))\n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        \n",
    "                \n",
    "        for i in range(self.max_iter):                \n",
    "            t = -(self.grads[-1]@self.directions[-1])/(self.directions[-1].T@self.hess(x0)@self.directions[-1])\n",
    "            self.ts.append(t)\n",
    "            \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            \n",
    "            self.xs.append(x)\n",
    "            self.funcs.append(self.f(x))\n",
    "            self.grads.append(self.grad(x))\n",
    "            aux = (self.grads[-1].T@self.hess(x)@self.directions[-1])/(self.directions[-1].T@self.hess(x)@self.directions[-1])\n",
    "            d = -self.grads[-1] + aux*self.directions[-1]\n",
    "            self.directions.append(d)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*10, 'GRADIENTES CONJUGADOS (LINEAR)')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def CGNonLinear(self, x0, method='Fletcher-Reeves', t0=1, backtracking=True, alpha=0.1):\n",
    "        '''\n",
    "        Fletcher-Reeves CG method.\n",
    "        >>> x0: initial approximation\n",
    "        >>> method: Fletcher-Reeves, Polak-Ribiere, Hestenes-Stiefel\n",
    "        >>> t0: initial step for backtracking\n",
    "        >>> backtracking: True, False\n",
    "        >>> alpha: Armijo search\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.ts = []\n",
    "        self.xs = []\n",
    "        \n",
    "        self.xs.append(x0)\n",
    "        self.funcs.append(self.f(x0))\n",
    "        self.grads.append(self.grad(x0))\n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        \n",
    "        for i in range(self.max_iter):                \n",
    "            t = t0\n",
    "            if backtracking==True:\n",
    "                while self.f(x0+t*self.directions[-1]) >= self.f(x0)+t*alpha*(self.grads[-1].T@self.directions[-1]):\n",
    "                    t=t/2\n",
    "            self.ts.append(t)\n",
    "            \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            \n",
    "            self.xs.append(x)\n",
    "            self.funcs.append(self.f(x))\n",
    "            self.grads.append(self.grad(x))\n",
    "            if method=='Fletcher-Reeves':\n",
    "                beta = (self.grads[-1].T@self.grads[-1])/(self.grads[-2].T@self.grads[-2])\n",
    "            elif method=='Polak-Ribiere':\n",
    "                beta = (self.grads[-1].T@(self.grads[-1]-self.grads[-2]))/(self.grads[-2].T@self.grads[-2])\n",
    "            elif method=='Hestenes-Stiefel':\n",
    "                beta=(self.grads[-1].T@(self.grads[-1]-self.grads[-2]))/((self.grads[-1]-self.grads[-2]).T@self.directions[-1])\n",
    "            else:\n",
    "                raise ValueError('Method not found!')\n",
    "            d = -self.grads[-1] + beta*self.directions[-1]\n",
    "            self.directions.append(d)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*17, method.upper())\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def CD(self, x0, method='sequential', t0=1, backtracking=True, alpha=0.1):\n",
    "        '''\n",
    "        CD method.\n",
    "        >>> x0: initial approximation\n",
    "        >>> method: sequential, random\n",
    "        >>> t0: initial step for backtracking\n",
    "        >>> backtracking: True, False\n",
    "        >>> alpha: Armijo search\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.ts = []\n",
    "        self.xs = []\n",
    "                \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            if method=='sequential':\n",
    "                j = i%len(x0)\n",
    "            elif method=='random':\n",
    "                j = np.random.randint(low=0, high=len(x0))\n",
    "            else:\n",
    "                raise ValueError('Method not found')\n",
    "                \n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0))\n",
    "            self.grads.append(self.grad(x0))\n",
    "            aux_vec = np.zeros(self.grads[-1].shape)\n",
    "            aux_vec[j] = 1\n",
    "            self.directions.append(-self.grads[-1]*aux_vec)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            \n",
    "            t = t0\n",
    "            if backtracking==True:\n",
    "                while self.f(x0+t*self.directions[-1]) >= self.f(x0)+t*alpha*(self.grads[-1].T@self.directions[-1]):\n",
    "                    t=t/2\n",
    "            self.ts.append(t)\n",
    "            \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        if method=='sequential':\n",
    "            j = i%len(x0)\n",
    "        elif method=='random':\n",
    "            j = np.random.randint(low=0, high=len(x0))\n",
    "        else:\n",
    "            raise ValueError('Method not found')\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x))\n",
    "        self.grads.append(self.grad(x))\n",
    "        aux_vec = np.zeros(self.grads[-1].shape)\n",
    "        aux_vec[j] = 1\n",
    "        self.directions.append(-self.grads[-1]*aux_vec)\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        print('*'*50)\n",
    "        print(' '*17, method.upper())\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "                \n",
    "    def iterations(self, n_iter):\n",
    "        \n",
    "        print(f'Aproximação inicial: {np.round(self.xs[0],5)}')\n",
    "        print(f'Valor da função: {np.round(self.funcs[0],5)}')\n",
    "        print(f'Gradiente: {np.round(self.grads[0],5)}')\n",
    "        print(f'Direção: {np.round(self.directions[0],5)}')\n",
    "        print(f'Norma do gradiente: {np.round(self.grad_norms[0],5)}')\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            print('-'*50)\n",
    "            print(' '*20, '{}ª iteração'.format(i+1))\n",
    "            print('-'*50)\n",
    "            print()\n",
    "            print(f'x: {np.round(self.xs[i+1],5)}')\n",
    "            print(f'Valor do passo: {np.round(self.ts[i],5)}')\n",
    "            print(f'Valor da função: {np.round(self.funcs[i+1],5)}')\n",
    "            print(f'Gradiente: {np.round(self.grads[i+1],5)}')\n",
    "            print(f'Direção: {np.round(self.directions[i+1],5)}')\n",
    "            print(f'Norma do gradiente: {np.round(self.grad_norms[i+1],5)}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimization(f, grad, hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Passo constante: $t=0.99(2/L)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO DO GRADIENTE\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 9\n",
      "Gradiente: [2. 8.]\n",
      "Direção: [-2. -8.]\n",
      "Norma do gradiente: 8.24621\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.01 -1.96]\n",
      "Valor do passo: 0.495\n",
      "Valor da função: 7.6833\n",
      "Gradiente: [ 0.02 -7.84]\n",
      "Direção: [-0.02  7.84]\n",
      "Norma do gradiente: 7.84003\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.0000e-04 1.9208e+00]\n",
      "Valor do passo: 0.495\n",
      "Valor da função: 7.37895\n",
      "Gradiente: [2.0000e-04 7.6832e+00]\n",
      "Direção: [-2.0000e-04 -7.6832e+00]\n",
      "Norma do gradiente: 7.6832\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.      -1.88238]\n",
      "Valor do passo: 0.495\n",
      "Valor da função: 7.08674\n",
      "Gradiente: [ 0.      -7.52954]\n",
      "Direção: [-0.       7.52954]\n",
      "Norma do gradiente: 7.52954\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.      1.84474]\n",
      "Valor do passo: 0.495\n",
      "Valor da função: 6.8061\n",
      "Gradiente: [0.      7.37895]\n",
      "Direção: [-0.      -7.37895]\n",
      "Norma do gradiente: 7.37895\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.GradientDescent(x0, method='constant', t0=(0.99*2/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Passo constante: $t_{0}=1$  com **BACKTRACKING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO DO GRADIENTE\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 9\n",
      "Gradiente: [2. 8.]\n",
      "Direção: [-2. -8.]\n",
      "Norma do gradiente: 8.24621\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.5 0. ]\n",
      "Valor do passo: 0.25\n",
      "Valor da função: 0.25\n",
      "Gradiente: [1. 0.]\n",
      "Direção: [-1. -0.]\n",
      "Norma do gradiente: 1.0\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0. 0.]\n",
      "Valor do passo: 0.5\n",
      "Valor da função: 0.0\n",
      "Gradiente: [0. 0.]\n",
      "Direção: [-0. -0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.GradientDescent(x0, method='constant', t0=1, backtracking=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO DO GRADIENTE\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 9\n",
      "Gradiente: [2. 8.]\n",
      "Direção: [-2. -8.]\n",
      "Norma do gradiente: 8.24621\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.48485 -0.06061]\n",
      "Valor do passo: 0.25758\n",
      "Valor da função: 0.24242\n",
      "Gradiente: [ 0.9697  -0.24242]\n",
      "Direção: [-0.9697   0.24242]\n",
      "Norma do gradiente: 0.99954\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.02694 0.05387]\n",
      "Valor do passo: 0.47222\n",
      "Valor da função: 0.00653\n",
      "Gradiente: [0.05387 0.21549]\n",
      "Direção: [-0.05387 -0.21549]\n",
      "Norma do gradiente: 0.22212\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.01306 -0.00163]\n",
      "Valor do passo: 0.25758\n",
      "Valor da função: 0.00018\n",
      "Gradiente: [ 0.02612 -0.00653]\n",
      "Direção: [-0.02612  0.00653]\n",
      "Norma do gradiente: 0.02692\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.00073 0.00145]\n",
      "Valor do passo: 0.47222\n",
      "Valor da função: 0.0\n",
      "Gradiente: [0.00145 0.0058 ]\n",
      "Direção: [-0.00145 -0.0058 ]\n",
      "Norma do gradiente: 0.00598\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.GradientDescent(x0, method='cauchy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Cauchy com **BACKTRACKING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO DO GRADIENTE\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 9\n",
      "Gradiente: [2. 8.]\n",
      "Direção: [-2. -8.]\n",
      "Norma do gradiente: 8.24621\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.48485 -0.06061]\n",
      "Valor do passo: 0.25758\n",
      "Valor da função: 0.24242\n",
      "Gradiente: [ 0.9697  -0.24242]\n",
      "Direção: [-0.9697   0.24242]\n",
      "Norma do gradiente: 0.99954\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.02694 0.05387]\n",
      "Valor do passo: 0.47222\n",
      "Valor da função: 0.00653\n",
      "Gradiente: [0.05387 0.21549]\n",
      "Direção: [-0.05387 -0.21549]\n",
      "Norma do gradiente: 0.22212\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.01306 -0.00163]\n",
      "Valor do passo: 0.25758\n",
      "Valor da função: 0.00018\n",
      "Gradiente: [ 0.02612 -0.00653]\n",
      "Direção: [-0.02612  0.00653]\n",
      "Norma do gradiente: 0.02692\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.00073 0.00145]\n",
      "Valor do passo: 0.47222\n",
      "Valor da função: 0.0\n",
      "Gradiente: [0.00145 0.0058 ]\n",
      "Direção: [-0.00145 -0.0058 ]\n",
      "Norma do gradiente: 0.00598\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.GradientDescent(x0, method='cauchy', backtracking=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Gradientes Conjugados LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fCG(x):\n",
    "    return 1\n",
    "\n",
    "def gradCG(x):\n",
    "    return hessCG(x)@x\n",
    "\n",
    "def hessCG(x):\n",
    "    return np.diag([10, 20, 30, 40, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "           GRADIENTES CONJUGADOS (LINEAR)\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 1 1 1 1]\n",
      "Valor da função: 1\n",
      "Gradiente: [10 20 30 40 50]\n",
      "Direção: [-10 -20 -30 -40 -50]\n",
      "Norma do gradiente: 74.16198\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.75556  0.51111  0.26667  0.02222 -0.22222]\n",
      "Valor do passo: 0.02444\n",
      "Valor da função: 1\n",
      "Gradiente: [  7.55556  10.22222   8.        0.88889 -11.11111]\n",
      "Direção: [ -8.1916  -11.49432  -9.90815  -3.43309   7.93086]\n",
      "Norma do gradiente: 18.70367\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.46536  0.10392 -0.08434 -0.0994   0.05873]\n",
      "Valor do passo: 0.03543\n",
      "Valor da função: 1\n",
      "Gradiente: [ 4.65361  2.07831 -2.53012 -3.9759   2.93675]\n",
      "Direção: [-5.98387 -3.94491  0.92111  3.4184  -1.64883]\n",
      "Norma do gradiente: 7.5372\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.20349 -0.06872 -0.04403  0.0502  -0.01342]\n",
      "Valor do passo: 0.04376\n",
      "Valor da função: 1\n",
      "Gradiente: [ 2.0349  -1.3745  -1.32081  2.00805 -0.67114]\n",
      "Direção: [-3.32599  0.52334  1.51955 -1.27049  0.31539]\n",
      "Norma do gradiente: 3.50104\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [ 0.04356 -0.04356  0.02904 -0.01089  0.00174]\n",
      "Valor do passo: 0.04808\n",
      "Valor da função: 1\n",
      "Gradiente: [ 0.4356  -0.87121  0.87121 -0.4356   0.08712]\n",
      "Direção: [-0.95255  0.95255 -0.63503  0.23814 -0.0381 ]\n",
      "Norma do gradiente: 1.38025\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0. 0. 0. 0. 0.]\n",
      "Valor do passo: 0.04573\n",
      "Valor da função: 1\n",
      "Gradiente: [0. 0. 0. 0. 0.]\n",
      "Direção: [-0. -0.  0. -0. -0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optCG = Optimization(fCG, gradCG, hessCG, max_iter=10)\n",
    "x0CG = np.array([1, 1, 1, 1, 1])\n",
    "optCG.CGLinear(x0CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Fletcher-Reeves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                  FLETCHER-REEVES\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 9\n",
      "Gradiente: [2. 8.]\n",
      "Direção: [-2. -8.]\n",
      "Norma do gradiente: 8.24621\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.5 0. ]\n",
      "Valor do passo: 0.25\n",
      "Valor da função: 0.25\n",
      "Gradiente: [1. 0.]\n",
      "Direção: [-1.02941 -0.11765]\n",
      "Norma do gradiente: 1.0\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.01471 -0.05882]\n",
      "Valor do passo: 0.5\n",
      "Valor da função: 0.00714\n",
      "Gradiente: [-0.02941 -0.23529]\n",
      "Direção: [-0.02847  0.22868]\n",
      "Norma do gradiente: 0.23713\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.02182 -0.00165]\n",
      "Valor do passo: 0.25\n",
      "Valor da função: 0.00048\n",
      "Gradiente: [-0.04365 -0.00662]\n",
      "Direção: [0.04266 0.01454]\n",
      "Norma do gradiente: 0.04415\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.00049  0.00562]\n",
      "Valor do passo: 0.5\n",
      "Valor da função: 6e-05\n",
      "Gradiente: [-0.00099  0.02247]\n",
      "Direção: [ 0.01206 -0.01869]\n",
      "Norma do gradiente: 0.02249\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.CGNonLinear(x0, method='Fletcher-Reeves', t0=1, backtracking=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Polak-Ribiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                  POLAK-RIBIERE\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 9\n",
      "Gradiente: [2. 8.]\n",
      "Direção: [-2. -8.]\n",
      "Norma do gradiente: 8.24621\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.5 0. ]\n",
      "Valor do passo: 0.25\n",
      "Valor da função: 0.25\n",
      "Gradiente: [1. 0.]\n",
      "Direção: [-0.97059  0.11765]\n",
      "Norma do gradiente: 1.0\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.01471 0.05882]\n",
      "Valor do passo: 0.5\n",
      "Valor da função: 0.00714\n",
      "Gradiente: [0.02941 0.23529]\n",
      "Direção: [-0.05544 -0.23214]\n",
      "Norma do gradiente: 0.23713\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.00085 0.00079]\n",
      "Valor do passo: 0.25\n",
      "Valor da função: 0.0\n",
      "Gradiente: [0.00169 0.00315]\n",
      "Direção: [-9.2e-04  6.0e-05]\n",
      "Norma do gradiente: 0.00358\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-8.0e-05  8.5e-04]\n",
      "Valor do passo: 1\n",
      "Valor da função: 0.0\n",
      "Gradiente: [-0.00016  0.0034 ]\n",
      "Direção: [ 7.0e-05 -3.4e-03]\n",
      "Norma do gradiente: 0.00341\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.CGNonLinear(x0, method='Polak-Ribiere', t0=1, backtracking=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Hestenes-Stiefel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                  HESTENES-STIEFEL\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 9\n",
      "Gradiente: [2. 8.]\n",
      "Direção: [-2. -8.]\n",
      "Norma do gradiente: 8.24621\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.5 0. ]\n",
      "Valor do passo: 0.25\n",
      "Valor da função: 0.25\n",
      "Gradiente: [1. 0.]\n",
      "Direção: [-0.9697   0.12121]\n",
      "Norma do gradiente: 1.0\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.01515 0.06061]\n",
      "Valor do passo: 0.5\n",
      "Valor da função: 0.00758\n",
      "Gradiente: [0.0303  0.24242]\n",
      "Direção: [-0.05969 -0.23875]\n",
      "Norma do gradiente: 0.24431\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.00023 0.00092]\n",
      "Valor do passo: 0.25\n",
      "Valor da função: 0.0\n",
      "Gradiente: [0.00046 0.00367]\n",
      "Direção: [ 4.5e-04 -6.0e-05]\n",
      "Norma do gradiente: 0.0037\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.00023 0.00092]\n",
      "Valor do passo: 0.0\n",
      "Valor da função: 0.0\n",
      "Gradiente: [0.00046 0.00367]\n",
      "Direção: [-0.0009  -0.00362]\n",
      "Norma do gradiente: 0.0037\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.CGNonLinear(x0, method='Hestenes-Stiefel', t0=1, backtracking=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descenso Coordenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fDC(x):\n",
    "    x1, x2, x3 = x\n",
    "    return np.exp(x1-x3)*((x2-1)**2)+x1**2+x2**2+x3**2\n",
    "\n",
    "def gradDC(x):\n",
    "    output = np.zeros(3)\n",
    "    x1, x2, x3 = x\n",
    "    output[0] = np.exp(x1-x3)*((x2-1)**2)+2*x1\n",
    "    output[1] = np.exp(x1-x3)*2*(x2-1)+2*x2\n",
    "    output[2] = -np.exp(x1-x3)*((x2-1)**2)+2*x3\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Sequencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                  SEQUENTIAL\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 1 0]\n",
      "Valor da função: 5.0\n",
      "Gradiente: [4. 2. 0.]\n",
      "Direção: [-4. -0. -0.]\n",
      "Norma do gradiente: 4.47214\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.6 1.  0. ]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 3.56\n",
      "Gradiente: [3.2 2.  0. ]\n",
      "Direção: [-0. -2. -0.]\n",
      "Norma do gradiente: 3.77359\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.6 0.8 0. ]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 3.39812\n",
      "Gradiente: [ 3.39812 -0.38121 -0.19812]\n",
      "Direção: [-0.       0.       0.19812]\n",
      "Norma do gradiente: 3.42517\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.6     0.8     0.01981]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 3.39463\n",
      "Gradiente: [ 3.39423 -0.34235 -0.15461]\n",
      "Direção: [-3.39423  0.       0.     ]\n",
      "Norma do gradiente: 3.41496\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.26058 0.8     0.01981]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 2.36778\n",
      "Gradiente: [ 2.65948  0.2167  -0.09871]\n",
      "Direção: [-2.65948 -0.       0.     ]\n",
      "Norma do gradiente: 2.67012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optDC = Optimization(fDC, gradDC, max_iter=4)\n",
    "x0DC = np.array([2, 1, 0])\n",
    "optDC.CD(x0DC, method='sequential', t0=0.1, backtracking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Randomizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                  RANDOM\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 1 0]\n",
      "Valor da função: 5.0\n",
      "Gradiente: [4. 2. 0.]\n",
      "Direção: [-0. -0. -0.]\n",
      "Norma do gradiente: 4.47214\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [2. 1. 0.]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 5.0\n",
      "Gradiente: [4. 2. 0.]\n",
      "Direção: [-0. -0. -0.]\n",
      "Norma do gradiente: 4.47214\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [2. 1. 0.]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 5.0\n",
      "Gradiente: [4. 2. 0.]\n",
      "Direção: [-0. -2. -0.]\n",
      "Norma do gradiente: 4.47214\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [2.  0.8 0. ]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 4.93556\n",
      "Gradiente: [ 4.29556 -1.35562 -0.29556]\n",
      "Direção: [-0.       1.35562  0.     ]\n",
      "Norma do gradiente: 4.51408\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [2.      0.93556 0.     ]\n",
      "Valor do passo: 0.1\n",
      "Valor da função: 4.90596\n",
      "Gradiente: [ 4.03068  0.91886 -0.03068]\n",
      "Direção: [-0.      -0.91886  0.     ]\n",
      "Norma do gradiente: 4.1342\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optDC = Optimization(fDC, gradDC, max_iter=4)\n",
    "x0DC = np.array([2, 1, 0])\n",
    "optDC.CD(x0DC, method='random', t0=0.1, backtracking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções com dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, points):\n",
    "    output = []\n",
    "    for point in points:\n",
    "        a, b = point\n",
    "        output.append((x[0]-a)**2 + (x[1]-b)**2)\n",
    "        \n",
    "    return np.mean(np.array(output))\n",
    "\n",
    "def grad(x, points):\n",
    "    output = np.zeros(len(x))\n",
    "    \n",
    "    for point in points:\n",
    "        a, b = point   \n",
    "        output[0] += 2*(x[0]-a)\n",
    "        output[1] += 2*(x[1]-b)\n",
    "    \n",
    "    return output/len(points)\n",
    "\n",
    "def hess(x, points):\n",
    "    output = np.zeros((len(x), len(x)))\n",
    "    \n",
    "    output[0,0] = 2\n",
    "    output[0,1] = 0\n",
    "    output[1,0] = 0\n",
    "    output[1,1] = 2\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe de métodos de otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization():\n",
    "    '''\n",
    "    Class designed for solving a minimization problem.\\n\n",
    "    Initialization requires:\n",
    "    >>> Function\n",
    "    >>> Gradient\n",
    "    >>> Hessian (optional)\n",
    "    >>> max_iter (optional)\n",
    "    >>> precision (optional)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, function, gradient, hessian=None, max_iter=10, precision=1e-5):\n",
    "        self.f = function\n",
    "        self.grad = gradient\n",
    "        self.hess = hessian\n",
    "        self.max_iter = max_iter\n",
    "        self.precision = precision\n",
    "        \n",
    "    def StochasticGradient(self, x0, points, t=0.1):\n",
    "        '''\n",
    "        Stochastic Gradient Descent method.\n",
    "        >>> x0: initial approximation\n",
    "        >>> t: method step\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))         \n",
    "            k = np.random.randint(low=0, high=len(points))\n",
    "            self.grads.append(self.grad(x0, [points[k]]))\n",
    "            self.directions.append(-self.grads[-1])\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            self.samples.append(points[k])\n",
    "            \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))         \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        self.grads.append(self.grad(x, [points[k]]))\n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        self.samples.append(points[k])\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'GRADIENTE ESTOCÁSTICO')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def miniBatch(self, x0, points, batch_size=2, t=0.1):\n",
    "        '''\n",
    "        Mini-Batch Gradient Descent method.\n",
    "        >>> x0: initial approximation\n",
    "        >>> t: method step\n",
    "        >>> batch_size: number of points considered in each batch\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            minibatch = [points[k] for k in np.random.randint(low=0, high=len(points), size=batch_size)]\n",
    "            self.grads.append(self.grad(x0, minibatch))\n",
    "            self.directions.append(-self.grads[-1])\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            self.samples.append(minibatch)\n",
    "            \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))         \n",
    "        minibatch = [points[k] for k in np.random.randint(low=0, high=len(points), size=batch_size)]\n",
    "        self.grads.append(self.grad(x0, minibatch))\n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        self.samples.append(minibatch)\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'GRADIENTE MINI-BATCH')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def SVRG(self, x0, points, base_case=5, t=0.1):\n",
    "        '''\n",
    "        Stochastic Gradient with Variance Reduction.\n",
    "        >>> x0: initial approximation\n",
    "        >>> t: method step\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            if i==0 or i%base_case==0:\n",
    "                ponto_base = x0\n",
    "                grad_base = self.grad(x0, points)\n",
    "                self.grads.append(grad_base)\n",
    "                self.samples.append(points)\n",
    "            else:\n",
    "                k = np.random.randint(low=0, high=len(points))\n",
    "                grad_k = self.grad(x0, [points[k]])\n",
    "                grad_k_base = self.grad(ponto_base, [points[k]])                               \n",
    "                self.grads.append(grad_k-grad_k_base+grad_base)\n",
    "                self.samples.append(points[k])\n",
    "                \n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            self.directions.append(-self.grads[-1])\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        if i==0 or i%base_case==0:\n",
    "            ponto_base = x\n",
    "            grad_base = self.grad(x, points)\n",
    "            self.grads.append(grad_base)\n",
    "            self.samples.append(points)\n",
    "        else:\n",
    "            k = np.random.randint(low=0, high=len(points))\n",
    "            grad_k = self.grad(x, [points[k]])\n",
    "            grad_k_base = self.grad(ponto_base, [points[k]])                               \n",
    "            self.grads.append(grad_k-grad_k_base+grad_base)\n",
    "            self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))         \n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO SVRG')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def SAG(self, x0, points, t=0.1):\n",
    "        '''\n",
    "        SAG.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "        \n",
    "        grad_k = [np.zeros(len(x0)) for i in range(len(points))]\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            if i==0:\n",
    "                for k in range(len(points)):\n",
    "                    grad_k[k] = self.grad(x0, [points[k]])\n",
    "                self.grads.append(self.grad(x0, points))\n",
    "                self.samples.append(points)\n",
    "            else:\n",
    "                k = np.random.randint(low=0, high=len(points))\n",
    "                grad_k[k] = self.grad(x0, [points[k]])\n",
    "                grad_sag = np.mean(np.array(grad_k), axis=0)\n",
    "                self.grads.append(grad_sag)\n",
    "                self.samples.append(points[k])\n",
    "                \n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            self.directions.append(-self.grads[-1])\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        grad_k[k] = self.grad(x, [points[k]])\n",
    "        grad_sag = np.mean(np.array(grad_k), axis=0)\n",
    "        self.grads.append(grad_sag)\n",
    "        self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))         \n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO SAG')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def SAGA(self, x0, points, t=0.1):\n",
    "        '''\n",
    "        SAGA.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "        \n",
    "        grad_k = [np.zeros(len(x0)) for i in range(len(points))]\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            if i==0:\n",
    "                for k in range(len(points)):\n",
    "                    grad_k[k] = self.grad(x0, [points[k]])\n",
    "                self.grads.append(self.grad(x0, points))\n",
    "                self.samples.append(points)\n",
    "            else:\n",
    "                k = np.random.randint(low=0, high=len(points))\n",
    "                grad_k_new = self.grad(x0, [points[k]])\n",
    "                grad_saga = np.mean(np.array(grad_k), axis=0)\n",
    "                self.grads.append(grad_saga+grad_k_new-grad_k[k])\n",
    "                grad_k[k] = grad_k_new\n",
    "                self.samples.append(points[k])\n",
    "                \n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            self.directions.append(-self.grads[-1])\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = x0 + t*self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        grad_k_new = self.grad(x0, [points[k]])\n",
    "        grad_saga = np.mean(np.array(grad_k), axis=0)\n",
    "        self.grads.append(grad_saga+grad_k_new-grad_k[k])\n",
    "        grad_k[k] = grad_k_new\n",
    "        self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))         \n",
    "        self.directions.append(-self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO SAGA')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def Adagrad(self, x0, points, eta=0.01, epsilon=1e-8):\n",
    "        '''\n",
    "        Adagrad.\n",
    "        >>> x0: initial approximation\n",
    "        >>> eta: adaptative step parameter\n",
    "        >>> epsilon: parameter to avoid division by zero\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "        \n",
    "        G = np.zeros(len(x0))\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            k = np.random.randint(low=0, high=len(points))\n",
    "            self.grads.append(self.grad(x0, [points[k]]))\n",
    "            self.samples.append(points[k])\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            G += self.grads[-1]**2\n",
    "            d = (eta/np.sqrt(G+epsilon))*self.grads[-1]\n",
    "            self.directions.append(-d)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = x0 + self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        self.grads.append(self.grad(x, [points[k]]))\n",
    "        self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))\n",
    "        G += self.grads[-1]**2\n",
    "        d = (eta/np.sqrt(G+epsilon))*self.grads[-1]\n",
    "        self.directions.append(-d)\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO ADAGRAD')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def RMSProp(self, x0, points, eta=0.01, gamma=0.9, epsilon=1e-8):\n",
    "        '''\n",
    "        RMSProp.\n",
    "        >>> x0: initial approximation\n",
    "        >>> eta: adaptative step parameter\n",
    "        >>> epsilon: parameter to avoid division by zero\n",
    "        >>> gamma: weight assigned to past information provided by gradients\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "        \n",
    "        G = np.zeros(len(x0))\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            k = np.random.randint(low=0, high=len(points))\n",
    "            self.grads.append(self.grad(x0, [points[k]]))\n",
    "            self.samples.append(points[k])\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            G = gamma*G + (1-gamma)*self.grads[-1]**2\n",
    "            d = (eta/np.sqrt(G+epsilon))*self.grads[-1]\n",
    "            self.directions.append(-d)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = x0 + self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        self.grads.append(self.grad(x, [points[k]]))\n",
    "        self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))\n",
    "        G = gamma*G + (1-gamma)*self.grads[-1]**2\n",
    "        d = (eta/np.sqrt(G+epsilon))*self.grads[-1]\n",
    "        self.directions.append(-d)\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO RMSPROP')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def Polyak(self, x0, points, gamma=0.1, t=0.1):\n",
    "        '''\n",
    "        Moment - Polyak.\n",
    "        >>> x0: initial approximation\n",
    "        >>> t: method step\n",
    "        >>> gamma: weight assigned to past information provided by gradients\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "        \n",
    "        m = np.zeros(len(x0))\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            k = np.random.randint(low=0, high=len(points))\n",
    "            self.grads.append(self.grad(x0, [points[k]]))\n",
    "            self.samples.append(points[k])\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            m = gamma*m + t*self.grads[-1]\n",
    "            self.directions.append(-m)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = x0 + self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        self.grads.append(self.grad(x, [points[k]]))\n",
    "        self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))\n",
    "        m = gamma*m + t*self.grads[-1]\n",
    "        self.directions.append(-m)\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MOMENTO DE POLYAK')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def Nesterov(self, x0, points, gamma=0.1, t=0.1):\n",
    "        '''\n",
    "        Moment - Nesterov.\n",
    "        >>> x0: initial approximation\n",
    "        >>> t: method step\n",
    "        >>> gamma: weight assigned to past information provided by gradients\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "        \n",
    "        m = np.zeros(len(x0))\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            k = np.random.randint(low=0, high=len(points))\n",
    "            self.samples.append(points[k])\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            z = x0+gamma*m\n",
    "            self.grads.append(self.grad(z, [points[k]]))\n",
    "            self.directions.append(-t*self.grads[-1])\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = z + self.directions[-1]\n",
    "            m = x-x0\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))\n",
    "        z = x+gamma*m\n",
    "        self.grads.append(self.grad(z, [points[k]]))\n",
    "        self.directions.append(-t*self.grads[-1])\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MOMENTO DE NESTEROV')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def ADAM(self, x0, points, eta=0.01, gamma1=0.9, gamma2=0.999, epsilon=1e-8):\n",
    "        '''\n",
    "        ADAM.\n",
    "        >>> x0: initial approximation\n",
    "        >>> eta: adaptative step parameter\n",
    "        >>> epsilon: parameter to avoid division by zero\n",
    "        >>> gamma1: moving average parameter\n",
    "        >>> gamma2: weight assigned to past information provided by gradients\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.directions = []\n",
    "        self.grad_norms = []\n",
    "        self.samples = []\n",
    "        self.xs = []\n",
    "        \n",
    "        G = np.zeros(len(x0))\n",
    "        m = np.zeros(len(x0))\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            k = np.random.randint(low=0, high=len(points))\n",
    "            self.grads.append(self.grad(x0, [points[k]]))\n",
    "            self.samples.append(points[k])\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0, points))\n",
    "            G = gamma2*G + (1-gamma2)*self.grads[-1]**2\n",
    "            G_hat = G/(1-gamma2)\n",
    "            m = gamma1*m + (1-gamma1)*self.grads[-1]\n",
    "            m_hat = m/(1-gamma1)\n",
    "            self.directions.append(-m_hat)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "                       \n",
    "            x = x0 + (eta/(np.sqrt(G_hat)+epsilon))*self.directions[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "        \n",
    "        k = np.random.randint(low=0, high=len(points))\n",
    "        self.grads.append(self.grad(x, [points[k]]))\n",
    "        self.samples.append(points[k])\n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x, points))\n",
    "        G = gamma2*G + (1-gamma2)*self.grads[-1]**2\n",
    "        G_hat = G/(1-gamma2)\n",
    "        m = gamma1*m + (1-gamma1)*self.grads[-1]\n",
    "        m_hat = m/(1-gamma1)\n",
    "        self.directions.append(-m_hat)\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO ADAM')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "                       \n",
    "    def iterations(self, n_iter):\n",
    "        \n",
    "        print(f'Aproximação inicial: {np.round(self.xs[0],5)}')\n",
    "        print('Ponto selecionado:\\n', np.round(self.samples[0],5))\n",
    "        print(f'Valor da função: {np.round(self.funcs[0],5)}')\n",
    "        print(f'Gradiente: {np.round(self.grads[0],5)}')\n",
    "        print(f'Direção: {np.round(self.directions[0],5)}')\n",
    "        print(f'Norma do gradiente: {np.round(self.grad_norms[0],5)}')\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            print('-'*50)\n",
    "            print(' '*20, '{}ª iteração'.format(i+1))\n",
    "            print('-'*50)\n",
    "            print()\n",
    "            print(f'x: {np.round(self.xs[i+1],5)}')\n",
    "            print('Ponto selecionado:\\n', np.round(self.samples[i+1],5))\n",
    "            print(f'Valor da função: {np.round(self.funcs[i+1],5)}')\n",
    "            print(f'Gradiente: {np.round(self.grads[i+1],5)}')\n",
    "            print(f'Direção: {np.round(self.directions[i+1],5)}')\n",
    "            print(f'Norma do gradiente: {np.round(self.grad_norms[i+1],5)}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimization(f, grad, hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([2,3])\n",
    "points = [(1,0), (0,1), (-1,0), (0,-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Gradiente Estocástico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                GRADIENTE ESTOCÁSTICO\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [4. 4.]\n",
      "Direção: [-4. -4.]\n",
      "Norma do gradiente: 5.65685\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.6 2.6]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 10.32\n",
      "Gradiente: [3.2 7.2]\n",
      "Direção: [-3.2 -7.2]\n",
      "Norma do gradiente: 7.87909\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.28 1.88]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 6.1728\n",
      "Gradiente: [0.56 3.76]\n",
      "Direção: [-0.56 -3.76]\n",
      "Norma do gradiente: 3.80147\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.224 1.504]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 4.76019\n",
      "Gradiente: [4.448 3.008]\n",
      "Direção: [-4.448 -3.008]\n",
      "Norma do gradiente: 5.36962\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.7792 1.2032]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 3.05484\n",
      "Gradiente: [1.5584 4.4064]\n",
      "Direção: [-1.5584 -4.4064]\n",
      "Norma do gradiente: 4.67386\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.62336 0.76256]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.97008\n",
      "Gradiente: [1.24672 3.52512]\n",
      "Direção: [-1.24672 -3.52512]\n",
      "Norma do gradiente: 3.73909\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.49869 0.41005]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.41683\n",
      "Gradiente: [0.99738 2.8201 ]\n",
      "Direção: [-0.99738 -2.8201 ]\n",
      "Norma do gradiente: 2.99127\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.39895 0.12804]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.17556\n",
      "Gradiente: [ 0.7979  -1.74392]\n",
      "Direção: [-0.7979   1.74392]\n",
      "Norma do gradiente: 1.91779\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.31916 0.30243]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.19333\n",
      "Gradiente: [ 0.63832 -1.39514]\n",
      "Direção: [-0.63832  1.39514]\n",
      "Norma do gradiente: 1.53423\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.25533 0.44194]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.26051\n",
      "Gradiente: [-1.48934  0.88389]\n",
      "Direção: [ 1.48934 -0.88389]\n",
      "Norma do gradiente: 1.73188\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.40426 0.35356]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.28843\n",
      "Gradiente: [0.80853 2.70711]\n",
      "Direção: [-0.80853 -2.70711]\n",
      "Norma do gradiente: 2.82527\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.StochasticGradient(x0, points, t=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Gradiente Estocástico - MiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                GRADIENTE MINI-BATCH\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [[ 0 -1]\n",
      " [ 1  0]]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [3. 7.]\n",
      "Direção: [-3. -7.]\n",
      "Norma do gradiente: 7.61577\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.7 2.3]\n",
      "Ponto selecionado:\n",
      " [[ 1  0]\n",
      " [-1  0]]\n",
      "Valor da função: 9.18\n",
      "Gradiente: [3.4 4.6]\n",
      "Direção: [-3.4 -4.6]\n",
      "Norma do gradiente: 5.72014\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.36 1.84]\n",
      "Ponto selecionado:\n",
      " [[-1  0]\n",
      " [-1  0]]\n",
      "Valor da função: 6.2352\n",
      "Gradiente: [4.72 3.68]\n",
      "Direção: [-4.72 -3.68]\n",
      "Norma do gradiente: 5.98505\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.888 1.472]\n",
      "Ponto selecionado:\n",
      " [[-1  0]\n",
      " [-1  0]]\n",
      "Valor da função: 3.95533\n",
      "Gradiente: [3.776 2.944]\n",
      "Direção: [-3.776 -2.944]\n",
      "Norma do gradiente: 4.78804\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.5104 1.1776]\n",
      "Ponto selecionado:\n",
      " [[-1  0]\n",
      " [ 0 -1]]\n",
      "Valor da função: 2.64725\n",
      "Gradiente: [2.0208 3.3552]\n",
      "Direção: [-2.0208 -3.3552]\n",
      "Norma do gradiente: 3.91676\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.30832 0.84208]\n",
      "Ponto selecionado:\n",
      " [[-1  0]\n",
      " [ 0 -1]]\n",
      "Valor da função: 1.80416\n",
      "Gradiente: [1.61664 2.68416]\n",
      "Direção: [-1.61664 -2.68416]\n",
      "Norma do gradiente: 3.13341\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.14666 0.57366]\n",
      "Ponto selecionado:\n",
      " [[1 0]\n",
      " [1 0]]\n",
      "Valor da função: 1.3506\n",
      "Gradiente: [-1.70669  1.14733]\n",
      "Direção: [ 1.70669 -1.14733]\n",
      "Norma do gradiente: 2.05649\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.31732 0.45893]\n",
      "Ponto selecionado:\n",
      " [[1 0]\n",
      " [0 1]]\n",
      "Valor da função: 1.31131\n",
      "Gradiente: [-0.36535 -0.08214]\n",
      "Direção: [0.36535 0.08214]\n",
      "Norma do gradiente: 0.37447\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.35386 0.46714]\n",
      "Ponto selecionado:\n",
      " [[-1  0]\n",
      " [ 0  1]]\n",
      "Valor da função: 1.34344\n",
      "Gradiente: [ 1.70772 -0.06571]\n",
      "Direção: [-1.70772  0.06571]\n",
      "Norma do gradiente: 1.70898\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.18309 0.47372]\n",
      "Ponto selecionado:\n",
      " [[-1  0]\n",
      " [-1  0]]\n",
      "Valor da função: 1.25793\n",
      "Gradiente: [2.36618 0.94743]\n",
      "Direção: [-2.36618 -0.94743]\n",
      "Norma do gradiente: 2.54881\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.05353  0.37897]\n",
      "Ponto selecionado:\n",
      " [[ 1  0]\n",
      " [ 0 -1]]\n",
      "Valor da função: 1.14649\n",
      "Gradiente: [-1.10706  1.75795]\n",
      "Direção: [ 1.10706 -1.75795]\n",
      "Norma do gradiente: 2.07749\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.miniBatch(x0, points, batch_size=2, t=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Gradiente Estocástico - SVRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO SVRG\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [[ 1  0]\n",
      " [ 0  1]\n",
      " [-1  0]\n",
      " [ 0 -1]]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [4. 6.]\n",
      "Direção: [-4. -6.]\n",
      "Norma do gradiente: 7.2111\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.6 2.4]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 9.32\n",
      "Gradiente: [3.2 4.8]\n",
      "Direção: [-3.2 -4.8]\n",
      "Norma do gradiente: 5.76888\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.28 1.92]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 6.3248\n",
      "Gradiente: [2.56 3.84]\n",
      "Direção: [-2.56 -3.84]\n",
      "Norma do gradiente: 4.61511\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.024 1.536]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 4.40787\n",
      "Gradiente: [2.048 3.072]\n",
      "Direção: [-2.048 -3.072]\n",
      "Norma do gradiente: 3.69208\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.8192 1.2288]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 3.18104\n",
      "Gradiente: [1.6384 2.4576]\n",
      "Direção: [-1.6384 -2.4576]\n",
      "Norma do gradiente: 2.95367\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.65536 0.98304]\n",
      "Ponto selecionado:\n",
      " [[ 1  0]\n",
      " [ 0  1]\n",
      " [-1  0]\n",
      " [ 0 -1]]\n",
      "Valor da função: 2.39586\n",
      "Gradiente: [1.31072 1.96608]\n",
      "Direção: [-1.31072 -1.96608]\n",
      "Norma do gradiente: 2.36293\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.52429 0.78643]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.89335\n",
      "Gradiente: [1.04858 1.57286]\n",
      "Direção: [-1.04858 -1.57286]\n",
      "Norma do gradiente: 1.89035\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.41943 0.62915]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.57175\n",
      "Gradiente: [0.83886 1.25829]\n",
      "Direção: [-0.83886 -1.25829]\n",
      "Norma do gradiente: 1.51228\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.33554 0.50332]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.36592\n",
      "Gradiente: [0.67109 1.00663]\n",
      "Direção: [-0.67109 -1.00663]\n",
      "Norma do gradiente: 1.20982\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.26844 0.40265]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 1.23419\n",
      "Gradiente: [0.53687 0.80531]\n",
      "Direção: [-0.53687 -0.80531]\n",
      "Norma do gradiente: 0.96786\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.21475 0.32212]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 1.14988\n",
      "Gradiente: [0.4295  0.64425]\n",
      "Direção: [-0.4295  -0.64425]\n",
      "Norma do gradiente: 0.77429\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.SVRG(x0, points, base_case=5, t=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Gradiente Estocástico - SAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO SAG\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [[ 1  0]\n",
      " [ 0  1]\n",
      " [-1  0]\n",
      " [ 0 -1]]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [4. 6.]\n",
      "Direção: [-4. -6.]\n",
      "Norma do gradiente: 7.2111\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.6 2.4]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 9.32\n",
      "Gradiente: [3.8 5.7]\n",
      "Direção: [-3.8 -5.7]\n",
      "Norma do gradiente: 6.85055\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.22 1.83]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 5.8373\n",
      "Gradiente: [3.41  5.115]\n",
      "Direção: [-3.41  -5.115]\n",
      "Norma do gradiente: 6.14746\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.879  1.3185]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 3.51108\n",
      "Gradiente: [2.8495  4.27425]\n",
      "Direção: [-2.8495  -4.27425]\n",
      "Norma do gradiente: 5.13701\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.59405 0.89107]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 2.14691\n",
      "Gradiente: [2.70702 4.06054]\n",
      "Direção: [-2.70702 -4.06054]\n",
      "Norma do gradiente: 4.88016\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.32335 0.48502]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.3398\n",
      "Gradiente: [2.2587  3.38805]\n",
      "Direção: [-2.2587  -3.38805]\n",
      "Norma do gradiente: 4.07193\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.09748 0.14622]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.03088\n",
      "Gradiente: [1.30744 1.96116]\n",
      "Direção: [-1.30744 -1.96116]\n",
      "Norma do gradiente: 2.35702\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.03327 -0.0499 ]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 1.0036\n",
      "Gradiente: [0.99378 1.49067]\n",
      "Direção: [-0.99378 -1.49067]\n",
      "Norma do gradiente: 1.79156\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.13264 -0.19897]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 1.05718\n",
      "Gradiente: [0.94409 1.41614]\n",
      "Direção: [-0.94409 -1.41614]\n",
      "Norma do gradiente: 1.70198\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.22705 -0.34058]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.16755\n",
      "Gradiente: [0.03056 0.04585]\n",
      "Direção: [-0.03056 -0.04585]\n",
      "Norma do gradiente: 0.0551\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.23011 -0.34516]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.17209\n",
      "Gradiente: [0.02904 0.04355]\n",
      "Direção: [-0.02904 -0.04355]\n",
      "Norma do gradiente: 0.05234\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.SAG(x0, points, t=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Gradiente Estocástico - SAGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO SAGA\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [[ 1  0]\n",
      " [ 0  1]\n",
      " [-1  0]\n",
      " [ 0 -1]]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [4. 6.]\n",
      "Direção: [-4. -6.]\n",
      "Norma do gradiente: 7.2111\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.6 2.4]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 9.32\n",
      "Gradiente: [3.2 4.8]\n",
      "Direção: [-3.2 -4.8]\n",
      "Norma do gradiente: 5.76888\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.28 1.92]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 6.3248\n",
      "Gradiente: [3.16 4.74]\n",
      "Direção: [-3.16 -4.74]\n",
      "Norma do gradiente: 5.69677\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.964 1.446]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 4.02021\n",
      "Gradiente: [1.568 2.352]\n",
      "Direção: [-1.568 -2.352]\n",
      "Norma do gradiente: 2.82675\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.8072 1.2108]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 3.11761\n",
      "Gradiente: [2.8084 4.2126]\n",
      "Direção: [-2.8084 -4.2126]\n",
      "Norma do gradiente: 5.06292\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.52636 0.78954]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.90043\n",
      "Gradiente: [2.48192 3.72288]\n",
      "Direção: [-2.48192 -3.72288]\n",
      "Norma do gradiente: 4.47434\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.27817 0.41725]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.25148\n",
      "Gradiente: [2.4068  3.61019]\n",
      "Direção: [-2.4068  -3.61019]\n",
      "Norma do gradiente: 4.33891\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.03749 0.05623]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.00457\n",
      "Gradiente: [2.29772 3.44659]\n",
      "Direção: [-2.29772 -3.44659]\n",
      "Norma do gradiente: 4.14228\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.19228 -0.28843]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.12016\n",
      "Gradiente: [-0.28582 -0.42874]\n",
      "Direção: [0.28582 0.42874]\n",
      "Norma do gradiente: 0.51528\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.1637  -0.24555]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.08709\n",
      "Gradiente: [-2.4048 -3.6072]\n",
      "Direção: [2.4048 3.6072]\n",
      "Norma do gradiente: 4.33532\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.07678 0.11517]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.01916\n",
      "Gradiente: [1.32171 1.98257]\n",
      "Direção: [-1.32171 -1.98257]\n",
      "Norma do gradiente: 2.38275\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.SAGA(x0, points, t=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO ADAGRAD\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [6. 6.]\n",
      "Direção: [-0.01 -0.01]\n",
      "Norma do gradiente: 8.48528\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.99 2.99]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 13.9002\n",
      "Gradiente: [3.98 7.98]\n",
      "Direção: [-0.00553 -0.00799]\n",
      "Norma do gradiente: 8.91744\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.98447 2.98201]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.8305\n",
      "Gradiente: [1.96894 5.96401]\n",
      "Direção: [-0.00264 -0.00513]\n",
      "Norma do gradiente: 6.28062\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.98183 2.97688]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.78948\n",
      "Gradiente: [1.96367 5.95376]\n",
      "Direção: [-0.00254 -0.00456]\n",
      "Norma do gradiente: 6.26923\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.97929 2.97232]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.75229\n",
      "Gradiente: [1.95858 5.94464]\n",
      "Direção: [-0.00246 -0.00414]\n",
      "Norma do gradiente: 6.25898\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.97683 2.96818]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.71796\n",
      "Gradiente: [1.95366 5.93636]\n",
      "Direção: [-0.00238 -0.00382]\n",
      "Norma do gradiente: 6.24957\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.97445 2.96436]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.68587\n",
      "Gradiente: [1.9489  5.92872]\n",
      "Direção: [-0.00231 -0.00357]\n",
      "Norma do gradiente: 6.24082\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.97214 2.96079]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 13.65561\n",
      "Gradiente: [3.94427 7.92159]\n",
      "Direção: [-0.00424 -0.0043 ]\n",
      "Norma do gradiente: 8.84923\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.9679  2.95649]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.61346\n",
      "Gradiente: [1.93579 5.91298]\n",
      "Direção: [-0.00204 -0.00306]\n",
      "Norma do gradiente: 6.22179\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.96586 2.95343]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.58738\n",
      "Gradiente: [1.93172 5.90687]\n",
      "Direção: [-0.00199 -0.00292]\n",
      "Norma do gradiente: 6.21471\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.96387 2.95051]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 13.56231\n",
      "Gradiente: [5.92774 5.90103]\n",
      "Direção: [-0.00522 -0.0028 ]\n",
      "Norma do gradiente: 8.36422\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.Adagrad(x0, points, eta=0.01, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO RMSPROP\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [4. 8.]\n",
      "Direção: [-0.03162 -0.03162]\n",
      "Norma do gradiente: 8.94427\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.96838 2.96838]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.68577\n",
      "Gradiente: [1.93675 5.93675]\n",
      "Direção: [-0.01438 -0.01948]\n",
      "Norma do gradiente: 6.24468\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.954   2.94889]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 13.5141\n",
      "Gradiente: [3.908   7.89779]\n",
      "Direção: [-0.02198 -0.02067]\n",
      "Norma do gradiente: 8.81178\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.93202 2.92822]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.30717\n",
      "Gradiente: [1.86404 5.85644]\n",
      "Direção: [-0.01043 -0.01439]\n",
      "Norma do gradiente: 6.14594\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.92159 2.91383]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.1829\n",
      "Gradiente: [1.84317 5.82766]\n",
      "Direção: [-0.01028 -0.01362]\n",
      "Norma do gradiente: 6.11219\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.9113  2.90021]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 13.06429\n",
      "Gradiente: [5.82261 5.80042]\n",
      "Direção: [-0.02323 -0.01302]\n",
      "Norma do gradiente: 8.21873\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.88807 2.88719]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 12.90066\n",
      "Gradiente: [1.77615 5.77437]\n",
      "Direção: [-0.00727 -0.01254]\n",
      "Norma do gradiente: 6.04136\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.8808  2.87464]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 12.80098\n",
      "Gradiente: [3.76161 7.74928]\n",
      "Direção: [-0.01444 -0.01548]\n",
      "Norma do gradiente: 8.614\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.86636 2.85917]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 12.65814\n",
      "Gradiente: [1.73273 5.71833]\n",
      "Direção: [-0.00684 -0.01125]\n",
      "Norma do gradiente: 5.97509\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.85952 2.84792]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 12.56844\n",
      "Gradiente: [1.71904 5.69583]\n",
      "Direção: [-0.00698 -0.01107]\n",
      "Norma do gradiente: 5.94959\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.85254 2.83685]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 12.47962\n",
      "Gradiente: [3.70508 7.6737 ]\n",
      "Direção: [-0.01418 -0.01407]\n",
      "Norma do gradiente: 8.52134\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.RMSProp(x0, points, eta=0.01, gamma=0.9, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Momento de Polyak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MOMENTO DE POLYAK\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [6. 6.]\n",
      "Direção: [-0.6 -0.6]\n",
      "Norma do gradiente: 8.48528\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.4 2.4]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 8.72\n",
      "Gradiente: [0.8 4.8]\n",
      "Direção: [-0.14 -0.54]\n",
      "Norma do gradiente: 4.86621\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.26 1.86]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 6.0472\n",
      "Gradiente: [2.52 5.72]\n",
      "Direção: [-0.266 -0.626]\n",
      "Norma do gradiente: 6.2505\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.994 1.234]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 3.51079\n",
      "Gradiente: [3.988 2.468]\n",
      "Direção: [-0.4254 -0.3094]\n",
      "Norma do gradiente: 4.6899\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.5686 0.9246]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 2.17819\n",
      "Gradiente: [ 1.1372 -0.1508]\n",
      "Direção: [-0.15626 -0.01586]\n",
      "Norma do gradiente: 1.14715\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.41234 0.90874]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.99583\n",
      "Gradiente: [-1.17532  1.81748]\n",
      "Direção: [ 0.10191 -0.18333]\n",
      "Norma do gradiente: 2.1644\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.51425 0.72541]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 1.79066\n",
      "Gradiente: [-0.97151  1.45081]\n",
      "Direção: [ 0.10734 -0.16341]\n",
      "Norma do gradiente: 1.74605\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.62159 0.56199]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.70221\n",
      "Gradiente: [ 1.24317 -0.87602]\n",
      "Direção: [-0.11358  0.07126]\n",
      "Norma do gradiente: 1.52082\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.508   0.63325]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.65908\n",
      "Gradiente: [1.01601 3.2665 ]\n",
      "Direção: [-0.11296 -0.31952]\n",
      "Norma do gradiente: 3.42086\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.39504 0.31373]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.25449\n",
      "Gradiente: [0.79009 2.62745]\n",
      "Direção: [-0.0903 -0.2947]\n",
      "Norma do gradiente: 2.74368\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.30474 0.01903]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.09323\n",
      "Gradiente: [0.60948 2.03806]\n",
      "Direção: [-0.06998 -0.23328]\n",
      "Norma do gradiente: 2.12724\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.Polyak(x0, points, gamma=0.1, t=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Momento de Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MOMENTO DE NESTEROV\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [2. 6.]\n",
      "Direção: [-0.2 -0.6]\n",
      "Norma do gradiente: 6.32456\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.8 2.4]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 10.0\n",
      "Gradiente: [5.56 4.68]\n",
      "Direção: [-0.556 -0.468]\n",
      "Norma do gradiente: 7.26746\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.224 1.872]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 6.00256\n",
      "Gradiente: [4.3328 3.6384]\n",
      "Direção: [-0.43328 -0.36384]\n",
      "Norma do gradiente: 5.65784\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.73312 1.45536]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 3.65554\n",
      "Gradiente: [1.36806 4.82739]\n",
      "Direção: [-0.13681 -0.48274]\n",
      "Norma do gradiente: 5.0175\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.54723 0.93096]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 2.16614\n",
      "Gradiente: [ 1.05727 -0.24297]\n",
      "Direção: [-0.10573  0.0243 ]\n",
      "Norma do gradiente: 1.08483\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.42291 0.90281]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 1.99392\n",
      "Gradiente: [2.82095 1.8    ]\n",
      "Direção: [-0.2821 -0.18  ]\n",
      "Norma do gradiente: 3.34631\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.12838 0.72   ]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 1.53488\n",
      "Gradiente: [2.19786 1.40344]\n",
      "Direção: [-0.21979 -0.14034]\n",
      "Norma do gradiente: 2.60772\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.12086  0.56137]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 1.32975\n",
      "Gradiente: [-0.29156  3.09102]\n",
      "Direção: [ 0.02916 -0.3091 ]\n",
      "Norma do gradiente: 3.10474\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.11662  0.23641]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.06949\n",
      "Gradiente: [-0.2324  -1.59217]\n",
      "Direção: [0.02324 0.15922]\n",
      "Norma do gradiente: 1.60905\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.09296  0.36313]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.14051\n",
      "Gradiente: [-0.18119 -1.2484 ]\n",
      "Direção: [0.01812 0.12484]\n",
      "Norma do gradiente: 1.26148\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.07248  0.50064]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 1.2559\n",
      "Gradiente: [-0.14085 -0.97121]\n",
      "Direção: [0.01409 0.09712]\n",
      "Norma do gradiente: 0.98137\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.Nesterov(x0, points, gamma=0.1, t=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Momento ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO ADAM\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [2 3]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 14.0\n",
      "Gradiente: [2. 6.]\n",
      "Direção: [-2. -6.]\n",
      "Norma do gradiente: 6.32456\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.99 2.99]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.9002\n",
      "Gradiente: [1.98 5.98]\n",
      "Direção: [ -3.78 -11.38]\n",
      "Norma do gradiente: 6.29927\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.97657 2.97656]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 13.76674\n",
      "Gradiente: [3.95313 7.95313]\n",
      "Direção: [ -7.35513 -18.19513]\n",
      "Norma do gradiente: 8.88141\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.9614 2.9609]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.61402\n",
      "Gradiente: [1.92281 5.92179]\n",
      "Direção: [ -8.54243 -22.29741]\n",
      "Norma do gradiente: 6.22614\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.94503 2.94379]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 13.44902\n",
      "Gradiente: [1.89006 5.88758]\n",
      "Direção: [ -9.57824 -25.95524]\n",
      "Norma do gradiente: 6.18352\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.92776 2.92563]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 13.27556\n",
      "Gradiente: [3.85551 7.85126]\n",
      "Direção: [-12.47593 -31.21098]\n",
      "Norma do gradiente: 8.74684\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.90928 2.90649]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 13.093\n",
      "Gradiente: [3.81856 3.81297]\n",
      "Direção: [-15.04689 -31.90285]\n",
      "Norma do gradiente: 5.39631\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.88987 2.88742]\n",
      "Ponto selecionado:\n",
      " [0 1]\n",
      "Valor da função: 12.90882\n",
      "Gradiente: [3.77975 3.77484]\n",
      "Direção: [-17.32195 -32.48741]\n",
      "Norma do gradiente: 5.3419\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.86978 2.86847]\n",
      "Ponto selecionado:\n",
      " [-1  0]\n",
      "Valor da função: 12.72424\n",
      "Gradiente: [5.73957 5.73695]\n",
      "Direção: [-21.32932 -34.97562]\n",
      "Norma do gradiente: 8.11512\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.84919 2.84912]\n",
      "Ponto selecionado:\n",
      " [1 0]\n",
      "Valor da função: 12.53698\n",
      "Gradiente: [1.69837 5.69824]\n",
      "Direção: [-20.89476 -37.1763 ]\n",
      "Norma do gradiente: 5.94596\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [1.82926 2.82949]\n",
      "Ponto selecionado:\n",
      " [ 0 -1]\n",
      "Valor da função: 12.35225\n",
      "Gradiente: [3.65853 7.65899]\n",
      "Direção: [-22.46381 -41.11766]\n",
      "Norma do gradiente: 8.48793\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.ADAM(x0, points, eta=0.01, gamma1=0.9, gamma2=0.999, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de Segunda Ordem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return np.exp(x1+x2)+x1**2+x2**2\n",
    "\n",
    "def grad(x):\n",
    "    x1, x2 = x\n",
    "    output = np.zeros(len(x))\n",
    "    output[0] = np.exp(x1+x2)+2*x1\n",
    "    output[1] = np.exp(x1+x2)+2*x2\n",
    "    \n",
    "    return output\n",
    "\n",
    "def hess(x):\n",
    "    x1, x2 = x\n",
    "    output = np.zeros((len(x), len(x)))\n",
    "    output[0,0] = np.exp(x1+x2)+2\n",
    "    output[0,1] = np.exp(x1+x2)\n",
    "    output[1,0] = np.exp(x1+x2)\n",
    "    output[1,1] = np.exp(x1+x2)+2\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe de métodos de otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization():\n",
    "    '''\n",
    "    Class designed for solving a minimization problem.\\n\n",
    "    Initialization requires:\n",
    "    >>> Function\n",
    "    >>> Gradient\n",
    "    >>> Hessian (optional)\n",
    "    >>> max_iter (optional)\n",
    "    >>> precision (optional)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, function, gradient, hessian=None, max_iter=10, precision=1e-5):\n",
    "        self.f = function\n",
    "        self.grad = gradient\n",
    "        self.hess = hessian\n",
    "        self.max_iter = max_iter\n",
    "        self.precision = precision\n",
    "        \n",
    "    def Newton(self, x0):\n",
    "        '''\n",
    "        Newton for minimization problems.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.Ms = []\n",
    "        self.grad_norms = []\n",
    "        self.ds = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0))         \n",
    "            self.grads.append(self.grad(x0))\n",
    "            self.Ms.append(self.hess(x0))\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            self.ds.append(np.linalg.solve(self.Ms[-1], -self.grads[-1]))\n",
    "            \n",
    "            x = x0 + self.ds[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x))         \n",
    "        self.grads.append(self.grad(x))\n",
    "        self.Ms.append(self.hess(x))\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        self.ds.append(np.linalg.solve(self.Ms[-1], -self.grads[-1]))\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO DE NEWTON')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def BFGS(self, x0):\n",
    "        '''\n",
    "        BFGS for minimization problems.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.Ms = []\n",
    "        self.grad_norms = []\n",
    "        self.ds = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0))         \n",
    "            self.grads.append(self.grad(x0))\n",
    "            if i==0:\n",
    "                self.Ms.append(self.hess(x0))\n",
    "            else:\n",
    "                s = (self.xs[-1] - self.xs[-2]).reshape(-1,1)\n",
    "                y = (self.grads[-1] - self.grads[-2]).reshape(-1,1)\n",
    "                M_new = self.Ms[-1] + (y@y.T)/(y.T@s) - (self.Ms[-1]@s@s.T@self.Ms[-1])/(s.T@self.Ms[-1]@s)\n",
    "                self.Ms.append(M_new)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            self.ds.append(np.linalg.solve(self.Ms[-1], -self.grads[-1]))\n",
    "            \n",
    "            x = x0 + self.ds[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x))         \n",
    "        self.grads.append(self.grad(x))\n",
    "        self.Ms.append(self.hess(x))\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        self.ds.append(np.linalg.solve(self.Ms[-1], -self.grads[-1]))\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO BFGS')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "        \n",
    "    def DFP(self, x0):\n",
    "        '''\n",
    "        DFP for minimization problems.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.Ms = []\n",
    "        self.grad_norms = []\n",
    "        self.ds = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0))         \n",
    "            self.grads.append(self.grad(x0))\n",
    "            if i==0:\n",
    "                hess_inv = np.linalg.inv(self.hess(x0))\n",
    "                self.Ms.append(hess_inv)\n",
    "            else:\n",
    "                s = (self.xs[-1] - self.xs[-2]).reshape(-1,1)\n",
    "                y = (self.grads[-1] - self.grads[-2]).reshape(-1,1)\n",
    "                M_new = self.Ms[-1] + (s@s.T)/(y.T@s) - (self.Ms[-1]@y@y.T@self.Ms[-1])/(y.T@self.Ms[-1]@y)\n",
    "                self.Ms.append(M_new)\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            self.ds.append(self.Ms[-1]@(-self.grads[-1]))\n",
    "            \n",
    "            x = x0 + self.ds[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x))         \n",
    "        self.grads.append(self.grad(x))\n",
    "        s = (self.xs[-1] - self.xs[-2]).reshape(-1,1)\n",
    "        y = (self.grads[-1] - self.grads[-2]).reshape(-1,1)\n",
    "        M_new = self.Ms[-1] + (s@s.T)/(y.T@s) - (self.Ms[-1]@y@y.T@self.Ms[-1])/(y.T@self.Ms[-1]@y)\n",
    "        self.Ms.append(M_new)\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        self.ds.append(self.Ms[-1]@(-self.grads[-1]))\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO DFP')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1, display=2)\n",
    "        print()\n",
    "        \n",
    "    def Broyden(self, x0, method=1):\n",
    "        '''\n",
    "        DFP for minimization problems.\n",
    "        >>> x0: initial approximation\n",
    "        >>> method: (1, 2)\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.Ms = []\n",
    "        self.grad_norms = []\n",
    "        self.ds = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0))         \n",
    "            self.grads.append(self.grad(x0))\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            if i==0:\n",
    "                if method==1:\n",
    "                    self.Ms.append(self.hess(x0))\n",
    "                else:\n",
    "                    hess_inv = np.linalg.inv(self.hess(x0))\n",
    "                    self.Ms.append(hess_inv)\n",
    "                self.ds.append(np.linalg.solve(self.Ms[-1], -self.grads[-1]))\n",
    "            else:\n",
    "                s = (self.xs[-1] - self.xs[-2]).reshape(-1,1)\n",
    "                y = (self.grads[-1] - self.grads[-2]).reshape(-1,1)\n",
    "                if method==1:\n",
    "                    M_new = self.Ms[-1] + ((y-self.Ms[-1]@s)@s.T)/(s.T@s)\n",
    "                else:\n",
    "                    M_new = self.Ms[-1] + ((s-self.Ms[-1]@y)@y.T)/(y.T@y)\n",
    "                self.Ms.append(M_new)\n",
    "                self.ds.append(self.Ms[-1]@(-self.grads[-1]))\n",
    "            \n",
    "            x = x0 + self.ds[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x))         \n",
    "        self.grads.append(self.grad(x))\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        s = (self.xs[-1] - self.xs[-2]).reshape(-1,1)\n",
    "        y = (self.grads[-1] - self.grads[-2]).reshape(-1,1)\n",
    "        if method==1:\n",
    "            M_new = self.Ms[-1] + ((y-self.Ms[-1]@s)@s.T)/(s.T@s)\n",
    "        else:\n",
    "            M_new = self.Ms[-1] + ((s-self.Ms[-1]@y)@y.T)/(y.T@y)\n",
    "        self.Ms.append(M_new)\n",
    "        self.ds.append(self.Ms[-1]@(-self.grads[-1]))\n",
    "\n",
    "        print('*'*50)\n",
    "        print(' '*15, 'MÉTODO DE BROYDEN {}'.format(method))\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        if method==1:\n",
    "            self.iterations(i+1, display=1)\n",
    "        else:\n",
    "            self.iterations(i+1, display=2)\n",
    "        print()\n",
    "        \n",
    "    def BarzilaiBorwein(self, x0):\n",
    "        '''\n",
    "        Barzilai-Borwein for minimization problems.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.Ms = []\n",
    "        self.grad_norms = []\n",
    "        self.ds = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0))         \n",
    "            self.grads.append(self.grad(x0))\n",
    "            if i==0:\n",
    "                t = (self.grads[-1].T@self.grads[-1])/(self.grads[-1].T@self.hess(x0)@self.grads[-1])\n",
    "                while self.f(x0-t*self.grads[-1]) >= self.f(x0)-0.1*t*(self.grads[-1].T@self.grads[-1]):\n",
    "                    t/=2\n",
    "            else:\n",
    "                s = (self.xs[-1] - self.xs[-2])\n",
    "                y = (self.grads[-1] - self.grads[-2])\n",
    "                t = (s.T@s)/(s.T@y)\n",
    "            self.Ms.append(1/t*np.eye(len(x0)))\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            self.ds.append(-t*self.grads[-1])\n",
    "            \n",
    "            x = x0 + self.ds[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x))         \n",
    "        self.grads.append(self.grad(x))\n",
    "        s = (self.xs[-1] - self.xs[-2]).reshape(-1,1)\n",
    "        y = (self.grads[-1] - self.grads[-2]).reshape(-1,1)\n",
    "        t = (s.T@s)/(s.T@y)\n",
    "        self.Ms.append(1/t*np.eye(len(x0)))\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        self.ds.append(-t*self.grads[-1])\n",
    "        \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'BARZILAI-BORWEIN')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "    def LevenbergMarquardt(self, x0, rho=0):\n",
    "        '''\n",
    "        Levenberg-Marquardt for minimization problems.\n",
    "        >>> x0: initial approximation\n",
    "        '''\n",
    "        \n",
    "        self.funcs = []\n",
    "        self.grads = []\n",
    "        self.Ms = []\n",
    "        self.grad_norms = []\n",
    "        self.ds = []\n",
    "        self.xs = []\n",
    "                   \n",
    "        for i in range(self.max_iter):\n",
    "            self.xs.append(x0)\n",
    "            self.funcs.append(self.f(x0))         \n",
    "            self.grads.append(self.grad(x0))\n",
    "            hess_approx = self.grads[-1].reshape(-1,1).T@self.grads[-1].reshape(-1,1)\n",
    "            self.Ms.append(hess_approx+rho*np.eye(len(x0)))\n",
    "            self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "            self.ds.append(np.linalg.solve(self.Ms[-1], -self.grads[-1]))\n",
    "            \n",
    "            x = x0 + self.ds[-1]\n",
    "            x0 = x\n",
    "            \n",
    "            if self.grad_norms[-1] < self.precision:\n",
    "                break\n",
    "                \n",
    "        self.xs.append(x)\n",
    "        self.funcs.append(self.f(x))         \n",
    "        self.grads.append(self.grad(x))\n",
    "        hess_approx = self.grads[-1].reshape(-1,1).T@self.grads[-1].reshape(-1,1)\n",
    "        self.Ms.append(hess_approx+rho*np.eye(len(x0)))\n",
    "        self.grad_norms.append(np.linalg.norm(self.grads[-1], ord=2))\n",
    "        self.ds.append(np.linalg.solve(self.Ms[-1], -self.grads[-1]))\n",
    "                \n",
    "        print('*'*50)\n",
    "        print(' '*15, 'LEVENBERG-MARQUARDT')\n",
    "        print('*'*50)\n",
    "        print()\n",
    "        self.iterations(i+1)\n",
    "        print()\n",
    "\n",
    "    def iterations(self, n_iter, display=1):\n",
    "        \n",
    "        print(f'Aproximação inicial: {np.round(self.xs[0],5)}')\n",
    "        print(f'Valor da função: {np.round(self.funcs[0],5)}')\n",
    "        print(f'Gradiente: {np.round(self.grads[0],5)}')\n",
    "        print(f'Norma do gradiente: {np.round(self.grad_norms[0],5)}')\n",
    "        print()\n",
    "        print('Sistema:')\n",
    "        if display==1:\n",
    "            print(f'{np.round(self.Ms[0],5)} dk = {-np.round(self.grads[0],5)}')\n",
    "        else:\n",
    "            print(f'dk = {np.round(self.Ms[0],5)} {-np.round(self.grads[0],5)}')\n",
    "        print(f'dk: {np.round(self.ds[0],5)}')\n",
    "        print()\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            print('-'*50)\n",
    "            print(' '*20, '{}ª iteração'.format(i+1))\n",
    "            print('-'*50)\n",
    "            print()\n",
    "            print(f'x: {np.round(self.xs[i+1],5)}')\n",
    "            print(f'Valor da função: {np.round(self.funcs[i+1],5)}')\n",
    "            print(f'Gradiente: {np.round(self.grads[i+1],5)}')\n",
    "            print(f'Norma do gradiente: {np.round(self.grad_norms[i+1],5)}')\n",
    "            print()\n",
    "            print('Sistema:')\n",
    "            if display==1:\n",
    "                print(f'{np.round(self.Ms[i+1],5)} dk = {-np.round(self.grads[i+1],5)}')\n",
    "            else:\n",
    "                print(f'dk = {np.round(self.Ms[0],5)} {-np.round(self.grads[0],5)}')\n",
    "            print(f'dk: {np.round(self.ds[i+1],5)}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimization(f, grad, hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Método de Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO DE NEWTON\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 25.08554\n",
      "Gradiente: [22.08554 24.08554]\n",
      "Norma do gradiente: 32.67849\n",
      "\n",
      "Sistema:\n",
      "[[22.08554 20.08554]\n",
      " [20.08554 22.08554]] dk = [-22.08554 -24.08554]\n",
      "dk: [-0.04743 -1.04743]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.95257 0.95257]\n",
      "Valor da função: 8.5352\n",
      "Gradiente: [8.62555 8.62555]\n",
      "Norma do gradiente: 12.19837\n",
      "\n",
      "Sistema:\n",
      "[[8.7204 6.7204]\n",
      " [6.7204 8.7204]] dk = [-8.62555 -8.62555]\n",
      "dk: [-0.55862 -0.55862]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.39395 0.39395]\n",
      "Valor da função: 2.50919\n",
      "Gradiente: [2.9867 2.9867]\n",
      "Norma do gradiente: 4.22383\n",
      "\n",
      "Sistema:\n",
      "[[4.19879 2.19879]\n",
      " [2.19879 4.19879]] dk = [-2.9867 -2.9867]\n",
      "dk: [-0.46685 -0.46685]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.07289 -0.07289]\n",
      "Valor da função: 0.87497\n",
      "Gradiente: [0.71855 0.71855]\n",
      "Norma do gradiente: 1.01619\n",
      "\n",
      "Sistema:\n",
      "[[2.86434 0.86434]\n",
      " [0.86434 2.86434]] dk = [-0.71855 -0.71855]\n",
      "dk: [-0.19271 -0.19271]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.2656 -0.2656]\n",
      "Valor da função: 0.72899\n",
      "Gradiente: [0.05669 0.05669]\n",
      "Norma do gradiente: 0.08017\n",
      "\n",
      "Sistema:\n",
      "[[2.58789 0.58789]\n",
      " [0.58789 2.58789]] dk = [-0.05669 -0.05669]\n",
      "dk: [-0.01785 -0.01785]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28345 -0.28345]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0.00037 0.00037]\n",
      "Norma do gradiente: 0.00052\n",
      "\n",
      "Sistema:\n",
      "[[2.56728 0.56728]\n",
      " [0.56728 2.56728]] dk = [-0.00037 -0.00037]\n",
      "dk: [-0.00012 -0.00012]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28357 -0.28357]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0. 0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "Sistema:\n",
      "[[2.56714 0.56714]\n",
      " [0.56714 2.56714]] dk = [-0. -0.]\n",
      "dk: [-0. -0.]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28357 -0.28357]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0. 0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "Sistema:\n",
      "[[2.56714 0.56714]\n",
      " [0.56714 2.56714]] dk = [-0. -0.]\n",
      "dk: [-0.  0.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.Newton(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO BFGS\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 25.08554\n",
      "Gradiente: [22.08554 24.08554]\n",
      "Norma do gradiente: 32.67849\n",
      "\n",
      "Sistema:\n",
      "[[22.08554 20.08554]\n",
      " [20.08554 22.08554]] dk = [-22.08554 -24.08554]\n",
      "dk: [-0.04743 -1.04743]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.95257 0.95257]\n",
      "Valor da função: 8.5352\n",
      "Gradiente: [8.62555 8.62555]\n",
      "Norma do gradiente: 12.19837\n",
      "\n",
      "Sistema:\n",
      "[[14.28543 12.20371]\n",
      " [12.20371 14.20741]] dk = [-8.62555 -8.62555]\n",
      "dk: [-0.31989 -0.33234]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.63269 0.62023]\n",
      "Valor da função: 4.28552\n",
      "Gradiente: [4.76591 4.741  ]\n",
      "Norma do gradiente: 6.72243\n",
      "\n",
      "Sistema:\n",
      "[[6.95893 4.91529]\n",
      " [4.91529 6.9573 ]] dk = [-4.76591 -4.741  ]\n",
      "dk: [-0.40628 -0.39441]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.2264  0.22582]\n",
      "Valor da função: 1.67407\n",
      "Gradiente: [2.02462 2.02346]\n",
      "Norma do gradiente: 2.86242\n",
      "\n",
      "Sistema:\n",
      "[[4.42965 2.3874 ]\n",
      " [2.3874  4.43092]] dk = [-2.02462 -2.02346]\n",
      "dk: [-0.29726 -0.2965 ]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.07085 -0.07068]\n",
      "Valor da função: 0.87804\n",
      "Gradiente: [0.72632 0.72667]\n",
      "Norma do gradiente: 1.02742\n",
      "\n",
      "Sistema:\n",
      "[[3.20668 1.16386]\n",
      " [1.16386 3.20679]] dk = [-0.72632 -0.72667]\n",
      "dk: [-0.16614 -0.1663 ]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.237   -0.23698]\n",
      "Valor da função: 0.73485\n",
      "Gradiente: [0.14853 0.14855]\n",
      "Norma do gradiente: 0.21007\n",
      "\n",
      "Sistema:\n",
      "[[2.75994 0.71705]\n",
      " [0.71705 2.7599 ]] dk = [-0.14853 -0.14855]\n",
      "dk: [-0.04271 -0.04273]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.27971 -0.27971]\n",
      "Valor da função: 0.72802\n",
      "Gradiente: [0.01212 0.01212]\n",
      "Norma do gradiente: 0.01714\n",
      "\n",
      "Sistema:\n",
      "[[2.61811 0.57523]\n",
      " [0.57523 2.6181 ]] dk = [-0.01212 -0.01212]\n",
      "dk: [-0.00379 -0.00379]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28351 -0.28351]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0.00021 0.00021]\n",
      "Norma do gradiente: 0.00029\n",
      "\n",
      "Sistema:\n",
      "[[2.59081 0.54794]\n",
      " [0.54794 2.59082]] dk = [-0.00021 -0.00021]\n",
      "dk: [-7.e-05 -7.e-05]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28357 -0.28357]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0. 0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "Sistema:\n",
      "[[2.58861 0.54574]\n",
      " [0.54574 2.58863]] dk = [-0. -0.]\n",
      "dk: [-0. -0.]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28357 -0.28357]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [ 0. -0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "Sistema:\n",
      "[[2.56714 0.56714]\n",
      " [0.56714 2.56714]] dk = [-0.  0.]\n",
      "dk: [-0.  0.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.BFGS(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ DFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                MÉTODO DFP\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 25.08554\n",
      "Gradiente: [22.08554 24.08554]\n",
      "Norma do gradiente: 32.67849\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.04743 -1.04743]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.95257 0.95257]\n",
      "Valor da função: 8.5352\n",
      "Gradiente: [8.62555 8.62555]\n",
      "Norma do gradiente: 12.19837\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.31628 -0.33548]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.63629 0.61709]\n",
      "Valor da função: 4.28785\n",
      "Gradiente: [4.77476 4.73636]\n",
      "Norma do gradiente: 6.72543\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.40935 -0.39155]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.22694 0.22554]\n",
      "Valor da função: 1.67459\n",
      "Gradiente: [2.0261 2.0233]\n",
      "Norma do gradiente: 2.86336\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.29779 -0.296  ]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.07085 -0.07046]\n",
      "Valor da função: 0.8782\n",
      "Gradiente: [0.72652 0.7273 ]\n",
      "Norma do gradiente: 1.028\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.16613 -0.16647]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.23697 -0.23693]\n",
      "Valor da função: 0.73486\n",
      "Gradiente: [0.14862 0.14871]\n",
      "Norma do gradiente: 0.21024\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.04273 -0.04278]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.2797  -0.27971]\n",
      "Valor da função: 0.72802\n",
      "Gradiente: [0.01214 0.01213]\n",
      "Norma do gradiente: 0.01716\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.0038 -0.0038]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28351 -0.28351]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0.00021 0.00021]\n",
      "Norma do gradiente: 0.00029\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-7.e-05 -7.e-05]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28357 -0.28357]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0. 0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0. -0.]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28357 -0.28357]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [ 0. -0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "Sistema:\n",
      "dk = [[ 0.26186 -0.23814]\n",
      " [-0.23814  0.26186]] [-22.08554 -24.08554]\n",
      "dk: [-0.  0.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.DFP(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Barzilai-Borwein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                BARZILAI-BORWEIN\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 25.08554\n",
      "Gradiente: [22.08554 24.08554]\n",
      "Norma do gradiente: 32.67849\n",
      "\n",
      "Sistema:\n",
      "[[42.09584  0.     ]\n",
      " [ 0.      42.09584]] dk = [-22.08554 -24.08554]\n",
      "dk: [-0.52465 -0.57216]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.47535 1.42784]\n",
      "Valor da função: 8.97195\n",
      "Gradiente: [7.65797 9.56295]\n",
      "Norma do gradiente: 12.2513\n",
      "\n",
      "Sistema:\n",
      "[[26.34922  0.     ]\n",
      " [ 0.      26.34922]] dk = [-7.65797 -9.56295]\n",
      "dk: [-0.29063 -0.36293]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.18472 1.06491]\n",
      "Valor da função: 4.65719\n",
      "Gradiente: [3.85848 5.61886]\n",
      "Norma do gradiente: 6.81611\n",
      "\n",
      "Sistema:\n",
      "[[11.72917  0.     ]\n",
      " [ 0.      11.72917]] dk = [-3.85848 -5.61886]\n",
      "dk: [-0.32896 -0.47905]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.14425  0.58586]\n",
      "Valor da função: 1.91925\n",
      "Gradiente: [1.26672 2.72693]\n",
      "Norma do gradiente: 3.00678\n",
      "\n",
      "Sistema:\n",
      "[[6.62698 0.     ]\n",
      " [0.      6.62698]] dk = [-1.26672 -2.72693]\n",
      "dk: [-0.19115 -0.41149]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.33539  0.17437]\n",
      "Valor da função: 0.99417\n",
      "Gradiente: [0.18049 1.20001]\n",
      "Norma do gradiente: 1.21351\n",
      "\n",
      "Sistema:\n",
      "[[4.06072 0.     ]\n",
      " [0.      4.06072]] dk = [-0.18049 -1.20001]\n",
      "dk: [-0.04445 -0.29552]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.37984 -0.12115]\n",
      "Valor da função: 0.76489\n",
      "Gradiente: [-0.15375  0.36364]\n",
      "Norma do gradiente: 0.3948\n",
      "\n",
      "Sistema:\n",
      "[[2.93395 0.     ]\n",
      " [0.      2.93395]] dk = [ 0.15375 -0.36364]\n",
      "dk: [ 0.0524  -0.12394]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.32744 -0.24509]\n",
      "Valor da função: 0.73138\n",
      "Gradiente: [-0.09077  0.07392]\n",
      "Norma do gradiente: 0.11707\n",
      "\n",
      "Sistema:\n",
      "[[2.16527 0.     ]\n",
      " [0.      2.16527]] dk = [ 0.09077 -0.07392]\n",
      "dk: [ 0.04192 -0.03414]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28551 -0.27923]\n",
      "Valor da função: 0.72799\n",
      "Gradiente: [-0.00252  0.01005]\n",
      "Norma do gradiente: 0.01036\n",
      "\n",
      "Sistema:\n",
      "[[2.01174 0.     ]\n",
      " [0.      2.01174]] dk = [ 0.00252 -0.01005]\n",
      "dk: [ 0.00125 -0.005  ]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28426 -0.28422]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [-0.00214 -0.00207]\n",
      "Norma do gradiente: 0.00297\n",
      "\n",
      "Sistema:\n",
      "[[2.29962 0.     ]\n",
      " [0.      2.29962]] dk = [0.00214 0.00207]\n",
      "dk: [0.00093 0.0009 ]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28333 -0.28333]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [0.00076 0.00077]\n",
      "Norma do gradiente: 0.00108\n",
      "\n",
      "Sistema:\n",
      "[[3.13346 0.     ]\n",
      " [0.      3.13346]] dk = [-0.00076 -0.00077]\n",
      "dk: [-0.00024 -0.00024]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [-0.28357 -0.28357]\n",
      "Valor da função: 0.72797\n",
      "Gradiente: [-0.  0.]\n",
      "Norma do gradiente: 0.0\n",
      "\n",
      "Sistema:\n",
      "[[3.13452 0.     ]\n",
      " [0.      3.13452]] dk = [ 0. -0.]\n",
      "dk: [[ 0. -0.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.BarzilaiBorwein(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Levenberg-Marquardt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "                LEVENBERG-MARQUARDT\n",
      "**************************************************\n",
      "\n",
      "Aproximação inicial: [1 2]\n",
      "Valor da função: 25.08554\n",
      "Gradiente: [22.08554 24.08554]\n",
      "Norma do gradiente: 32.67849\n",
      "\n",
      "Sistema:\n",
      "[[1167.88403 1067.88403]\n",
      " [1067.88403 1167.88403]] dk = [-22.08554 -24.08554]\n",
      "dk: [-0.00033 -0.02033]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     1ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.99967 1.97967]\n",
      "Valor da função: 24.59346\n",
      "Gradiente: [21.67435 23.63435]\n",
      "Norma do gradiente: 32.06805\n",
      "\n",
      "Sistema:\n",
      "[[1128.36003 1028.36003]\n",
      " [1028.36003 1128.36003]] dk = [-21.67435 -23.63435]\n",
      "dk: [-0.0007 -0.0203]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     2ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.99897 1.95937]\n",
      "Valor da função: 24.10305\n",
      "Gradiente: [21.26392 23.18472]\n",
      "Norma do gradiente: 31.45927\n",
      "\n",
      "Sistema:\n",
      "[[1089.68543  989.68543]\n",
      " [ 989.68543 1089.68543]] dk = [-21.26392 -23.18472]\n",
      "dk: [-0.00108 -0.02029]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     3ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.99789 1.93908]\n",
      "Valor da função: 23.61432\n",
      "Gradiente: [20.85429 22.73668]\n",
      "Norma do gradiente: 30.85219\n",
      "\n",
      "Sistema:\n",
      "[[1051.8579  951.8579]\n",
      " [ 951.8579 1051.8579]] dk = [-20.85429 -22.73668]\n",
      "dk: [-0.00147 -0.02029]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     4ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.99642 1.91879]\n",
      "Valor da função: 23.12729\n",
      "Gradiente: [20.44552 22.29026]\n",
      "Norma do gradiente: 30.2469\n",
      "\n",
      "Sistema:\n",
      "[[1014.87504  914.87504]\n",
      " [ 914.87504 1014.87504]] dk = [-20.44552 -22.29026]\n",
      "dk: [-0.00185 -0.0203 ]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     5ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.99457 1.89849]\n",
      "Valor da função: 22.64197\n",
      "Gradiente: [20.03767 21.84551]\n",
      "Norma do gradiente: 29.64345\n",
      "\n",
      "Sistema:\n",
      "[[978.73437 878.73437]\n",
      " [878.73437 978.73437]] dk = [-20.03767 -21.84551]\n",
      "dk: [-0.00224 -0.02031]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     6ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.99234 1.87818]\n",
      "Valor da função: 22.1584\n",
      "Gradiente: [19.63078 21.40247]\n",
      "Norma do gradiente: 29.04192\n",
      "\n",
      "Sistema:\n",
      "[[943.43332 843.43332]\n",
      " [843.43332 943.43332]] dk = [-19.63078 -21.40247]\n",
      "dk: [-0.00262 -0.02034]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     7ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.98971 1.85784]\n",
      "Valor da função: 21.6766\n",
      "Gradiente: [19.22493 20.96118]\n",
      "Norma do gradiente: 28.44238\n",
      "\n",
      "Sistema:\n",
      "[[908.96922 808.96922]\n",
      " [808.96922 908.96922]] dk = [-19.22493 -20.96118]\n",
      "dk: [-0.00301 -0.02038]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     8ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.9867  1.83746]\n",
      "Valor da função: 21.19662\n",
      "Gradiente: [18.82018 20.5217 ]\n",
      "Norma do gradiente: 27.84492\n",
      "\n",
      "Sistema:\n",
      "[[875.33931 775.33931]\n",
      " [775.33931 875.33931]] dk = [-18.82018 -20.5217 ]\n",
      "dk: [-0.00341 -0.02042]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     9ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.98329 1.81704]\n",
      "Valor da função: 20.71848\n",
      "Gradiente: [18.41658 20.08408]\n",
      "Norma do gradiente: 27.2496\n",
      "\n",
      "Sistema:\n",
      "[[842.54073 742.54073]\n",
      " [742.54073 842.54073]] dk = [-18.41658 -20.08408]\n",
      "dk: [-0.00381 -0.02048]\n",
      "\n",
      "--------------------------------------------------\n",
      "                     10ª iteração\n",
      "--------------------------------------------------\n",
      "\n",
      "x: [0.97948 1.79655]\n",
      "Valor da função: 20.24225\n",
      "Gradiente: [18.01422 19.64837]\n",
      "Norma do gradiente: 26.65653\n",
      "\n",
      "Sistema:\n",
      "[[810.5705 710.5705]\n",
      " [710.5705 810.5705]] dk = [-18.01422 -19.64837]\n",
      "dk: [-0.00421 -0.02055]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt.LevenbergMarquardt(x0, rho=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
